# Absolute or relative path from the running directory to the extraction template in xml with descriptions of the fields to be collected
template: "Vulnerability"
# template: "config/extraction_template.xml"

exemplars:
  filepath: "data/samples/extraction_samples.json"
  exemplars_key: "samples"
  prompt_key: "system_prompt"
  query_key: "document"
  response_key: "extraction"
  response_conversion_kwargs: 
    json_enclosure: true
    code_block_enclosure: true
    inplace: true
  sample_kwargs:
    k: 1
    random: true

model:
  model_class: "HFStrucGenLM" # choose for structure enforced model
  # model_class: "HFGenerativeLM" # choose for only basic model
  init_kwargs:
    model: "meta-llama/Llama-2-7b"
    torch_dtype: "bfloat16"
    # quantize_kwargs: "8bit" # use 8bit or 4bit or comment out for no quantization
    device_map: "ddp"
    torch_dtype: "bfloat16" 
    pad_token: "unk_token" 
    parser: "JsonSchemaParser" # comment out on using HFGenerativeLM model_class
  generation_config:
    max_new_tokens: 500
    top_p: 0.9
    temperature: 1
    do_sample: true
